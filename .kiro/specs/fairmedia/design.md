# Design Document: FAIRMEDIA

## Overview

FAIRMEDIA is an AI-powered bias audit and mitigation system that detects and reduces bias in digital media content through machine learning, natural language processing, and explainable AI techniques. The system provides transparent bias scoring, intelligent content re-weighting, and human-in-the-loop oversight to ensure ethical compliance.

The architecture follows a modular design with clear separation between bias detection, explainability, mitigation, and human review components. This enables independent development, testing, and improvement of each subsystem while maintaining a cohesive user experience.

**Key Design Principles:**
- **Transparency**: All bias detection and mitigation decisions must be explainable
- **Non-destructive**: Content is never edited or deleted, only re-weighted
- **Human oversight**: Critical decisions require human approval
- **Extensibility**: Support for multiple languages and bias types
- **Performance**: Real-time analysis for responsive user experience

## Architecture

The system follows a microservices-inspired architecture with the following major components:

```
┌─────────────────────────────────────────────────────────────┐
│                     API Gateway Layer                        │
│              (Authentication, Rate Limiting)                 │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                   Content Processing Pipeline                │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │   Language   │→ │     Bias     │→ │Explainability│     │
│  │   Detection  │  │   Detection  │  │    Engine    │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    Mitigation Layer                          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │  Re-weighting│  │    Human     │  │   Decision   │     │
│  │    Module    │  │   Review UI  │  │    Logger    │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                      Data Layer                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │   Content    │  │  Bias Reports│  │  Audit Logs  │     │
│  │   Storage    │  │   Database   │  │   Database   │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
```

**Component Responsibilities:**

1. **API Gateway**: Handles authentication, authorization, rate limiting, and request routing
2. **Language Detection**: Identifies the language of input content
3. **Bias Detection**: ML/NLP models that identify bias patterns
4. **Explainability Engine**: Generates human-readable explanations using attention mechanisms
5. **Re-weighting Module**: Calculates adjustment weights using ML techniques
6. **Human Review UI**: Web interface for reviewers to approve/reject mitigation
7. **Decision Logger**: Records all decisions for audit and model improvement
8. **Storage Layer**: Persists content, reports, and audit trails

## Components and Interfaces

### 1. API Gateway

**Purpose**: Entry point for all external requests, handles cross-cutting concerns.

**Interface**:
```python
class APIGateway:
    def authenticate(token: str) -> User:
        """Validates authentication token and returns user object"""
        
    def authorize(user: User, resource: str, action: str) -> bool:
        """Checks if user has permission for action on resource"""
        
    def rate_limit(user: User) -> bool:
        """Returns True if user is within rate limits"""
        
    def route_request(request: Request) -> Response:
        """Routes request to appropriate handler"""
```

**Dependencies**: User database, configuration service

### 2. Language Detection Module

**Purpose**: Identifies the language of input text to route to appropriate models.

**Interface**:
```python
class LanguageDetector:
    def detect_language(text: str) -> Language:
        """
        Detects the primary language of the input text.
        Returns Language object with ISO code and confidence score.
        """
        
    def is_supported(language: Language) -> bool:
        """Checks if language is supported for bias detection"""
```

**Implementation Approach**:
- Use pre-trained language identification model (e.g., fastText, langdetect)
- Support minimum: English, Spanish, Hindi, Mandarin
- Return confidence score for validation

### 3. Bias Detection Engine

**Purpose**: Core ML/NLP component that identifies bias patterns in text.

**Interface**:
```python
class BiasDetector:
    def detect_bias(text: str, language: Language) -> BiasAnalysis:
        """
        Analyzes text for bias patterns.
        Returns BiasAnalysis containing scores and evidence.
        """
        
    def detect_gender_bias(text: str, language: Language) -> BiasScore:
        """Detects gender-based bias patterns"""
        
    def detect_stereotypes(text: str, language: Language) -> BiasScore:
        """Detects stereotypical representations"""
        
    def detect_language_dominance(text: str, language: Language) -> BiasScore:
        """Detects language dominance patterns"""

class BiasAnalysis:
    content_id: str
    language: Language
    gender_bias_score: BiasScore
    stereotype_score: BiasScore
    language_dominance_score: BiasScore
    overall_score: float
    evidence: List[BiasEvidence]
    
class BiasScore:
    score: float  # 0.0 to 1.0, higher = more biased
    confidence: float  # 0.0 to 1.0
    bias_type: str
    
class BiasEvidence:
    text_span: Tuple[int, int]  # start, end positions
    text_content: str
    contribution: float  # how much this span contributes to bias
    explanation: str
```

**Implementation Approach**:
- Use transformer-based models (BERT, RoBERTa) fine-tuned on bias detection datasets
- Gender bias: Detect gendered language, role stereotypes, pronoun usage patterns
- Stereotypes: Identify associations between groups and attributes
- Language dominance: Detect English-centric references, cultural assumptions
- Use attention weights to identify contributing text spans

**Model Selection**:
- Base model: multilingual BERT or XLM-RoBERTa for cross-language support
- Fine-tune on bias-labeled datasets (e.g., WinoBias, StereoSet, CrowS-Pairs)
- Use ensemble of specialized models for each bias type

### 4. Explainability Engine

**Purpose**: Generates human-readable explanations for bias detection results.

**Interface**:
```python
class ExplainabilityEngine:
    def generate_explanation(analysis: BiasAnalysis) -> BiasReport:
        """
        Creates comprehensive bias report with explanations.
        Returns BiasReport with human-readable content.
        """
        
    def explain_score(score: BiasScore, evidence: List[BiasEvidence]) -> str:
        """Generates natural language explanation for a bias score"""
        
    def highlight_spans(text: str, evidence: List[BiasEvidence]) -> HighlightedText:
        """Creates annotated text with bias highlights"""

class BiasReport:
    content_id: str
    timestamp: datetime
    analysis: BiasAnalysis
    summary: str  # High-level summary
    detailed_explanations: Dict[str, str]  # Per bias type
    highlighted_text: HighlightedText
    recommendations: List[str]
    
class HighlightedText:
    original_text: str
    highlights: List[Highlight]
    
class Highlight:
    span: Tuple[int, int]
    severity: str  # "low", "medium", "high"
    bias_type: str
    explanation: str
```

**Implementation Approach**:
- Use attention weights from bias detection models
- Apply LIME or SHAP for model-agnostic explanations
- Generate natural language templates filled with specific evidence
- Provide severity-based color coding for visual interface

### 5. Re-weighting Module

**Purpose**: Calculates content influence adjustments without modifying original content.

**Interface**:
```python
class ReweightingModule:
    def calculate_weights(analysis: BiasAnalysis) -> WeightAdjustment:
        """
        Calculates re-weighting factors based on bias analysis.
        Returns WeightAdjustment with adjustment factors.
        """
        
    def apply_weights(content_id: str, weights: WeightAdjustment) -> bool:
        """Applies weight adjustments to content in recommendation system"""
        
    def simulate_impact(weights: WeightAdjustment, dataset: List[Content]) -> ImpactAnalysis:
        """Simulates the impact of weight adjustments on content distribution"""

class WeightAdjustment:
    content_id: str
    original_weight: float
    adjusted_weight: float
    adjustment_factor: float
    rationale: str
    
class ImpactAnalysis:
    before_distribution: Dict[str, float]
    after_distribution: Dict[str, float]
    bias_reduction: float
    diversity_improvement: float
```

**Implementation Approach**:
- Use inverse propensity scoring based on bias scores
- Higher bias → lower weight in recommendations
- Preserve content availability (weight ≥ 0.1, never zero)
- Use ML to learn optimal weight functions from human feedback
- Apply softmax normalization to maintain distribution properties

**Weight Calculation Formula**:
```
adjusted_weight = original_weight * (1 - α * bias_score)
where α is a learned sensitivity parameter (0 < α < 1)
```

### 6. Human Review Interface

**Purpose**: Web UI for human reviewers to approve/reject mitigation actions.

**Interface**:
```python
class ReviewInterface:
    def get_pending_reviews(reviewer: User) -> List[ReviewTask]:
        """Retrieves pending review tasks for a reviewer"""
        
    def display_review(task: ReviewTask) -> ReviewDisplay:
        """Prepares review task for display"""
        
    def submit_decision(task_id: str, decision: Decision, reviewer: User) -> bool:
        """Records reviewer decision"""

class ReviewTask:
    task_id: str
    content_id: str
    content_preview: str
    bias_report: BiasReport
    proposed_weights: WeightAdjustment
    impact_analysis: ImpactAnalysis
    priority: str  # "high", "medium", "low"
    created_at: datetime
    
class Decision:
    task_id: str
    action: str  # "approve", "reject", "modify"
    reviewer_notes: str
    modified_weights: Optional[WeightAdjustment]
    timestamp: datetime
```

**UI Components**:
- Dashboard: Queue of pending reviews, sorted by priority
- Review Panel: Side-by-side view of content and bias report
- Explanation View: Interactive visualization of bias evidence
- Decision Controls: Approve/Reject buttons with notes field
- Impact Preview: Shows effect of mitigation on content distribution

### 7. Decision Logger

**Purpose**: Records all decisions for audit trail and model improvement.

**Interface**:
```python
class DecisionLogger:
    def log_analysis(analysis: BiasAnalysis) -> str:
        """Logs bias analysis, returns log ID"""
        
    def log_decision(decision: Decision) -> str:
        """Logs human decision, returns log ID"""
        
    def log_mitigation(content_id: str, weights: WeightAdjustment) -> str:
        """Logs applied mitigation, returns log ID"""
        
    def query_logs(filters: LogFilter) -> List[LogEntry]:
        """Retrieves logs matching filter criteria"""
        
    def export_training_data() -> TrainingDataset:
        """Exports logged decisions for model retraining"""

class LogEntry:
    log_id: str
    timestamp: datetime
    event_type: str  # "analysis", "decision", "mitigation"
    content_id: str
    user_id: Optional[str]
    data: Dict[str, Any]
    
class TrainingDataset:
    analyses: List[BiasAnalysis]
    decisions: List[Decision]
    outcomes: List[MitigationOutcome]
```

**Implementation Approach**:
- Use structured logging with JSON format
- Store in time-series database for efficient querying
- Implement retention policies (90 days minimum)
- Provide export functionality for data science team

## Data Models

### Content Model

```python
class Content:
    content_id: str  # UUID
    text: str
    language: Language
    source: str  # origin platform/system
    metadata: Dict[str, Any]
    created_at: datetime
    processed_at: Optional[datetime]
    current_weight: float
    status: str  # "pending", "analyzed", "mitigated"
```

### User Model

```python
class User:
    user_id: str
    username: str
    email: str
    role: str  # "reviewer", "admin", "auditor", "api_client"
    permissions: List[str]
    created_at: datetime
    last_login: datetime
```

### Language Model

```python
class Language:
    iso_code: str  # ISO 639-1 code (e.g., "en", "es", "hi")
    name: str
    confidence: float  # detection confidence
    is_supported: bool
```

### Database Schema

**Content Table**:
- Primary key: content_id
- Indexes: language, status, created_at
- TTL: 30 days (configurable)

**BiasReports Table**:
- Primary key: report_id
- Foreign key: content_id
- Indexes: content_id, timestamp, overall_score
- TTL: 90 days

**AuditLogs Table**:
- Primary key: log_id
- Indexes: timestamp, event_type, content_id, user_id
- TTL: 90 days

**Users Table**:
- Primary key: user_id
- Unique: username, email
- Indexes: role

**Decisions Table**:
- Primary key: decision_id
- Foreign keys: task_id, reviewer_id, content_id
- Indexes: timestamp, action, reviewer_id


## Correctness Properties

*A property is a characteristic or behavior that should hold true across all valid executions of a system—essentially, a formal statement about what the system should do. Properties serve as the bridge between human-readable specifications and machine-verifiable correctness guarantees.*

### Property Reflection

After analyzing all acceptance criteria, I identified several areas of redundancy:

**Redundancy Group 1 - Content Preservation (3.2, 3.3, 3.4)**:
- All three criteria verify that original content remains unchanged during mitigation
- These can be combined into a single comprehensive property

**Redundancy Group 2 - Logging Completeness (5.5, 8.1, 8.2)**:
- All verify that events are logged with required metadata
- Can be combined into a single property about log entry completeness

**Redundancy Group 3 - Bias Type Detection (1.2, 1.3, 1.4, 1.5)**:
- All verify that specific bias types are detected
- Can be combined into a single property about comprehensive bias detection

**Redundancy Group 4 - Report Completeness (2.1, 2.2, 2.3, 2.4)**:
- All verify different aspects of report completeness
- Can be combined into a single property about complete bias reports

The following properties represent the unique, non-redundant validation requirements:

### Core Bias Detection Properties

**Property 1: ML-based bias detection**
*For any* content item submitted for analysis, the bias detector should process it using ML/NLP techniques and produce a bias analysis result.
**Validates: Requirements 1.1**

**Property 2: Comprehensive bias type detection**
*For any* analyzed text, the bias detector should generate scores for all three bias types (gender bias, stereotypes, and language dominance), with each score being a valid float between 0.0 and 1.0.
**Validates: Requirements 1.2, 1.3, 1.4, 1.5**

### Explainability Properties

**Property 3: Complete bias reports**
*For any* bias analysis, the generated bias report should include both quantitative scores and qualitative explanations, with specific text spans identified, contribution values quantified, and all fields populated.
**Validates: Requirements 2.1, 2.2, 2.3, 2.4**

### Mitigation Properties

**Property 4: Content preservation invariant**
*For any* content item that undergoes mitigation, the original text should remain byte-for-byte identical before and after re-weighting is applied.
**Validates: Requirements 3.2, 3.3, 3.4**

**Property 5: Weight calculation for biased content**
*For any* content with bias score above the threshold, the re-weighting module should calculate adjustment weights that reduce the content's influence (adjusted_weight < original_weight).
**Validates: Requirements 3.1**

### Multi-language Properties

**Property 6: Regional language processing**
*For any* content item in a supported regional language, the bias detector should successfully process it and return a complete bias analysis.
**Validates: Requirements 4.1**

**Property 7: Cross-language bias detection consistency**
*For any* content in a supported language, the bias analysis should include all three bias types regardless of the content's language.
**Validates: Requirements 4.2**

**Property 8: Language-matched explanations**
*For any* content analyzed in a regional language, the explanation text should be in the same language as the input content.
**Validates: Requirements 4.3**

### Human-in-the-Loop Properties

**Property 9: Approval requirement for mitigation**
*For any* bias mitigation recommendation, the system should not apply re-weighting until a human reviewer has explicitly approved the action.
**Validates: Requirements 5.1**

**Property 10: Review task completeness**
*For any* review task presented to a human reviewer, it should include the complete bias report with all analysis details.
**Validates: Requirements 5.2**

**Property 11: Approval triggers mitigation**
*For any* mitigation recommendation that receives human approval, the system should apply the proposed weight adjustments to the content.
**Validates: Requirements 5.3**

**Property 12: Rejection preserves state**
*For any* mitigation recommendation that is rejected by a human reviewer, the content's current weight should remain unchanged.
**Validates: Requirements 5.4**

### Audit and Logging Properties

**Property 13: Complete event logging**
*For any* system event (analysis, decision, or mitigation), the logged entry should include a timestamp, event type, content ID, and all relevant metadata for that event type.
**Validates: Requirements 5.5, 8.1, 8.2**

**Property 14: Report persistence**
*For any* generated bias report, it should be stored in the database and remain retrievable for audit purposes.
**Validates: Requirements 8.3**

**Property 15: Log searchability**
*For any* valid log filter criteria, the query should return all matching log entries in chronological order.
**Validates: Requirements 8.4**

**Property 16: Audit log retention**
*For any* log entry created, it should remain accessible for at least 90 days from creation.
**Validates: Requirements 8.5**

### Performance Properties

**Property 17: Analysis time bound**
*For any* content item up to 1000 words, the bias detection should complete within 5 seconds.
**Validates: Requirements 6.1**

**Property 18: Report generation time bound**
*For any* bias analysis, the report generation should complete within 2 seconds.
**Validates: Requirements 6.4**

**Property 19: UI responsiveness**
*For any* user interaction in the review interface, the system should provide feedback within 1 second.
**Validates: Requirements 11.3**

### Security Properties

**Property 20: Authentication requirement**
*For any* request to access protected resources, the system should reject requests without valid authentication credentials.
**Validates: Requirements 7.3, 10.3**

**Property 21: Authorization enforcement**
*For any* authenticated user attempting to access a resource, the system should only allow access if the user's role has the required permissions.
**Validates: Requirements 7.4**

**Property 22: Content retention policy**
*For any* content item stored for more than 30 days, it should either have explicit retention approval or be automatically deleted.
**Validates: Requirements 7.5**

### API Properties

**Property 23: JSON response format**
*For any* API response, the content type should be application/json and the body should be valid, parseable JSON.
**Validates: Requirements 10.4**

### Model Management Properties

**Property 24: Training data export**
*For any* set of logged human decisions, they should be exportable in a format suitable for model training.
**Validates: Requirements 9.1**

**Property 25: Model versioning**
*For any* deployed model, it should have a unique version identifier that enables rollback.
**Validates: Requirements 9.3**

**Property 26: Model performance metrics**
*For any* model version, performance metrics (precision, recall, F1) should be available for comparison.
**Validates: Requirements 9.4**

### Error Handling Properties

**Property 27: Failure logging and alerting**
*For any* component failure, the system should log the error with stack trace and send an alert to administrators.
**Validates: Requirements 12.2**

**Property 28: Recovery without data loss**
*For any* system failure and recovery, all data that was committed before the failure should remain intact and accessible.
**Validates: Requirements 12.3**

### UI Properties

**Property 29: Bias severity visualization**
*For any* bias report displayed in the UI, visual indicators (colors, icons) should be present to represent bias severity levels.
**Validates: Requirements 11.2**

## Error Handling

### Error Categories

1. **Input Validation Errors**
   - Invalid content format
   - Unsupported language
   - Content exceeds size limits
   - Missing required fields

2. **Processing Errors**
   - Model inference failures
   - Timeout during analysis
   - Resource exhaustion
   - External service unavailability

3. **Authorization Errors**
   - Invalid authentication token
   - Insufficient permissions
   - Expired session

4. **Data Errors**
   - Database connection failures
   - Data corruption
   - Constraint violations

### Error Handling Strategy

**Validation Errors**:
- Return HTTP 400 with detailed error message
- Include field-level validation errors
- Suggest corrections where possible

**Processing Errors**:
- Return HTTP 500 with generic error message (hide internal details)
- Log full error details internally
- Implement retry logic with exponential backoff
- Provide fallback responses when possible

**Authorization Errors**:
- Return HTTP 401 for authentication failures
- Return HTTP 403 for authorization failures
- Log security events for audit

**Data Errors**:
- Implement transaction rollback
- Log errors with context
- Alert administrators for critical failures
- Provide graceful degradation

### Error Response Format

```json
{
  "error": {
    "code": "BIAS_DETECTION_FAILED",
    "message": "Unable to analyze content",
    "details": "Content language could not be detected",
    "timestamp": "2024-01-15T10:30:00Z",
    "request_id": "req_abc123"
  }
}
```

### Circuit Breaker Pattern

Implement circuit breakers for external dependencies:
- ML model inference endpoints
- Database connections
- External APIs

States:
- **Closed**: Normal operation
- **Open**: Failures exceed threshold, reject requests immediately
- **Half-Open**: Test if service recovered

### Retry Strategy

- Idempotent operations: Retry up to 3 times with exponential backoff
- Non-idempotent operations: No automatic retry, return error
- Timeout: 30 seconds for analysis, 10 seconds for API calls

## Testing Strategy

### Dual Testing Approach

FAIRMEDIA requires both unit testing and property-based testing for comprehensive coverage:

**Unit Tests**: Focus on specific examples, edge cases, and integration points
- Specific bias detection examples (known biased text)
- Edge cases (empty content, very long content, special characters)
- Error conditions (invalid input, service failures)
- Integration between components

**Property-Based Tests**: Verify universal properties across all inputs
- Generate random content with various characteristics
- Test properties hold for all generated inputs
- Minimum 100 iterations per property test
- Catch edge cases that humans might miss

### Property-Based Testing Configuration

**Framework Selection**:
- Python: Use Hypothesis library
- TypeScript/JavaScript: Use fast-check library
- Each property test must run minimum 100 iterations

**Test Tagging**:
Each property test must include a comment tag:
```python
# Feature: fairmedia, Property 1: ML-based bias detection
def test_ml_based_detection(content):
    ...
```

**Property Test Structure**:
```python
from hypothesis import given, strategies as st

# Feature: fairmedia, Property 4: Content preservation invariant
@given(st.text(min_size=10, max_size=1000))
def test_content_preservation(original_text):
    # Create content
    content = create_content(original_text)
    
    # Apply mitigation
    apply_mitigation(content.id, weights)
    
    # Verify original unchanged
    retrieved = get_content(content.id)
    assert retrieved.text == original_text
```

### Unit Test Coverage

**Bias Detection Module**:
- Test with known biased examples from WinoBias dataset
- Test with neutral content
- Test with mixed bias types
- Test language detection accuracy
- Test with unsupported languages

**Explainability Engine**:
- Test explanation generation for high/medium/low bias
- Test span highlighting accuracy
- Test contribution score calculation
- Test multi-language explanations

**Re-weighting Module**:
- Test weight calculation formulas
- Test weight bounds (never zero)
- Test impact simulation accuracy
- Test with various bias score ranges

**Human Review Interface**:
- Test task queue ordering
- Test decision submission
- Test UI rendering with various report types
- Test keyboard navigation

**API Layer**:
- Test authentication flows
- Test authorization for different roles
- Test rate limiting
- Test error responses
- Test JSON schema validation

### Integration Testing

**End-to-End Workflows**:
1. Content submission → Analysis → Report generation
2. Analysis → Review task creation → Human decision → Mitigation
3. API authentication → Content submission → Report retrieval
4. Model training data export → Retraining → Deployment

**Component Integration**:
- Bias detector + Explainability engine
- Re-weighting module + Decision logger
- API gateway + All backend services

### Performance Testing

**Load Testing**:
- Test with 100 concurrent analysis requests
- Measure response times under load
- Verify no degradation in accuracy

**Stress Testing**:
- Test with content at size limits (10,000 words)
- Test with rapid request bursts
- Test memory usage over time

**Benchmarking**:
- Measure analysis time for various content sizes
- Measure report generation time
- Measure database query performance

### Security Testing

**Authentication Testing**:
- Test with invalid tokens
- Test with expired tokens
- Test token refresh flows

**Authorization Testing**:
- Test role-based access control
- Test privilege escalation attempts
- Test cross-user data access

**Input Validation Testing**:
- Test with malicious input (SQL injection, XSS)
- Test with malformed JSON
- Test with oversized payloads

### Test Data Management

**Bias Detection Test Data**:
- Curated examples from academic datasets (WinoBias, StereoSet, CrowS-Pairs)
- Synthetic examples covering all bias types
- Multi-language examples for each supported language

**Anonymization**:
- Remove PII from test data
- Use synthetic names and identifiers
- Comply with data protection regulations

### Continuous Testing

**Pre-commit Hooks**:
- Run unit tests
- Run linting and type checking
- Run fast property tests (10 iterations)

**CI/CD Pipeline**:
- Run full unit test suite
- Run full property test suite (100 iterations)
- Run integration tests
- Run security scans
- Generate coverage reports (target: 80% coverage)

**Model Validation**:
- Test new models against benchmark datasets
- Compare performance with previous versions
- Require human review before deployment

### Test Metrics

**Coverage Targets**:
- Unit test coverage: 80% minimum
- Property test coverage: All 29 properties implemented
- Integration test coverage: All critical workflows

**Quality Metrics**:
- All tests must pass before merge
- No flaky tests (tests must be deterministic or properly handle randomness)
- Test execution time: < 5 minutes for full suite

**Model Performance Metrics**:
- Bias detection precision: ≥ 75%
- Bias detection recall: ≥ 75%
- Explanation quality: ≥ 80% reviewer satisfaction
- False positive rate: ≤ 15%
